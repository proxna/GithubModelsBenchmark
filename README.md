# Github Copilot model benchmark
This repository contains a .NET solution designed to benchmark the performance of code generated by different Large Language Models (LLMs) available in GitHub Copilot.

## Testing Procedure

Four different models available in Github Copilot:

- GPT 4o (default model)
- GPT 4.1
- Gemini 2.5 Pro
- Claude 3.7 Sonnet

has been asked about creating method for returning prime numbers with focus on optimalization. All implementation has been generated based on following prompt

```
create method PrimeNumber[nameofmodel] which returns n prime number where n is parameter describes which number do we want to get, while creating the method focus on optimization
```

Extended thinking feature was disabled for all of models.

Next the program runs a benchmark for each implementation, which generates the sum of the first thousand prime numbers.

## Test results

Benchmark performed on following machine:

- Intel Core i7 11700F
- 64 GB RAM DDR4 3200 Mhz
- Windows 11 24H2

Provides following results:

```
| Method            | Mean      | Error     | StdDev    | Min       | Max       |
|------------------ |----------:|----------:|----------:|----------:|----------:|
| PrimeNumber4o     | 13.035 ms | 0.0630 ms | 0.0559 ms | 12.961 ms | 13.167 ms |
| PrimeNumberClaude | 22.457 ms | 0.0790 ms | 0.0700 ms | 22.378 ms | 22.619 ms |
| PrimeNumber41     |  5.181 ms | 0.0965 ms | 0.0991 ms |  5.057 ms |  5.352 ms |
| PrimeNumberGemini | 37.884 ms | 0.7095 ms | 0.6968 ms | 36.876 ms | 38.949 ms |
```

It means that GPT 4.1 is able to generate most optimized code.

## Running the Solution

### Prerequisites
- .NET 8.0 SDK or later
- Visual Studio 2022 or later (optional)

### Building and Running the Benchmarks
This application must be run in Release configuration for accurate benchmark results:

#### Using Command Line:
```bash
# Navigate to the solution directory
cd CopilotModelsBenchmark

# Build the solution in Release configuration
dotnet build -c Release

# Run the benchmark application
dotnet run -c Release --project CopilotModelsBenchmark/CopilotModelsBenchmark.csproj
```

#### Using Visual Studio:
1. Open `CopilotModelsBenchmark.sln` in Visual Studio
2. Change the build configuration to `Release` in the dropdown menu
3. Right-click on the `CopilotModelsBenchmark` project and select `Set as Startup Project`
4. Press `F5` or click the `Start` button to run the benchmarks

### Running Unit Tests
```bash
# Run all unit tests
dotnet test

# Run specific test project
dotnet test CopilotModelsBenchmark.Tests/CopilotModelsBenchmark.Tests.csproj
```

The benchmark results will show the performance comparison between different LLM-generated prime number calculation algorithms.

